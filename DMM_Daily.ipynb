{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "DMM - Daily.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shudaGutHub/saleem-andrew/blob/master/DMM_Daily.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0EyVg5A37yx",
        "colab_type": "text"
      },
      "source": [
        "# Daily MicroModels\n",
        "\n",
        "\n",
        "* **LuckySeven - \"LKY\"**\n",
        "    - LKY_numDSLR  int   (DaySinceLastRace <= 7)\n",
        "    - LKY_deltaR1HDWPSR int (difference from top HDWPSR) <= 5 \n",
        "    \n",
        "    \n",
        "    \n",
        "* **Sunrise - \"SUN\"**\n",
        "\n",
        "\n",
        "    - SUN_deltaR1HDWPSR int ( difference from top HDWPSR <= 3 )\n",
        "    - SUN_rankMLO_S2LF ( rank morning line odds between 4:8) \n",
        "\n",
        "\n",
        "* **Meatloaf - \"MLF\"**\n",
        "    \n",
        "    Uses *x8_race_class* along with historical jockey, trainer data coupled with historical median 'runner_HDWPSRRating' and current 'runner_HDWPSRRating', 'race_speed_HDW_par_class_level*\n",
        "    \n",
        "    - MLF_isJKY: {0,1} \n",
        "    - MLF_isTRN: {0,1}\n",
        "    - MLF_isHDWPSR: {0,1}\n",
        "    - MLF_numHDWPAR: float \n",
        "    - MLF_numHDWPSR: float \n",
        "    \n",
        "    \n",
        "* **ShowMeTheMoney - \"SMM\"**\n",
        "     \n",
        "     Uses *earnings_lifetime, earnings_prevYear, earnings_curYear* to find WN bets\n",
        "    \n",
        "    - SMM_rankEPS_LT_L2SF: int  \n",
        "    - SMM_rankEPS_CY_L2SF: int \n",
        "    - SMM_rankEPS_PY_L2SF: int \n",
        "    - SMM_rankEPS_PP_L2SF: int \n",
        "    \n",
        "    \n",
        "* **CarnivorousCoronavirus - \"CCV\"**\n",
        "\n",
        "    Uses *days_since_last_race , num_workouts_since_last_race* to find WN bets\n",
        "    - CCV_numWKSLR : int (ascending=False) more workouts is generally better\n",
        "    - CCV_catWKSLR : category\n",
        "    - CCV_numDSLR : int (ascending=True) less days is generally better\n",
        "   \n",
        "    \n",
        "  \n",
        "* **ThickerThanWater - \"TTW\"**\n",
        "\n",
        "    Uses *pedigree_DIRT, pedigree_DIST, pedigree_MUD, pedigree_TURF* to find WN bets \n",
        "    - TTW_rankPDIRT_L2SF : int \n",
        "    - TTW_rankPDIST_L2SF : int\n",
        "    - TTW_rankPMUD_L2SF : int\n",
        "    - TTW_rankPTURF_L2SF : int\n",
        "    - TTW_isDIRT_L2SF : int\n",
        "    - TTW_isGOOD_L2SF : int"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ETzyOz237yy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wrapper for JCapper Race files - aka Past Performance (.jcp)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import os\n",
        "from pandas import concat, DataFrame, read_csv, to_datetime, Series, MultiIndex\n",
        "from datetime import timedelta, datetime\n",
        "#from horse.betsim import data\n",
        "#from horse.bin.debug.simulate_vector import *\n",
        "#from s3fs.core import S3FileSystem\n",
        "#from horse.betsim.math import compute_probs_from_odds\n",
        "from scipy.stats import entropy\n",
        "from warnings import warn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3ZTXK_z37y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from horse.bin.debug.simulate_vector import *#add_residual_earnings, add_cumsum_reverse, add_runner_earnings_per_start_factors\n",
        "#from horse.betsim.wrap.daily import DailyRaces\n",
        "#from horse.betsim.wrap.pastperformance import PastPerformance\n",
        "#from horse.betsim.wrap.jcapper import JCapper\n",
        "from math import isclose"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a5bPh4537y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fp_track_detail = \"C:\\\\Users\\\\Saleem\\\\projects\\\\x8313\\\\data\\\\DMM\\\\track_detail.csv\"\n",
        "#fp_schema_pastperformance = \"C:\\\\Users\\\\Saleem\\\\projects\\\\x8313\\\\data\\\\DMM\\\\schema_pastperformance.csv\"\n",
        "#fp_rebates = \"C:\\\\Users\\\\Saleem\\\\projects\\\\x8313\\\\data\\\\DMM\\\\X8rebates.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-7RX9pe37y7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def load_track_detail():\n",
        "#    fp_track_detail = \"C:\\\\Users\\\\Saleem\\\\projects\\\\x8313\\\\data\\\\DMM\\\\track_detail.csv\"\n",
        "#    dftd = pd.read_csv(fp_track_detail,index_col=['itsp_track_sym'])\n",
        "#    return dftd\n",
        "    \n",
        "#def load_x8rebates():\n",
        "#    fp_x8rebates =  \"C:\\\\Users\\\\Saleem\\\\projects\\\\x8313\\\\data\\\\DMM\\\\X8rebates.csv\"\n",
        "#    dfx8rebates = pd.read_csv(fp_x8rebates,index_col=['itsp_track_sym'])#, usecols=['Win','Place', 'Show', 'Exacta', 'Trifecta', 'Superfecta', 'DD', 'P3', 'P4', 'P5', 'P6'])\n",
        "#    dfx8rebates.drop(columns=cols_prefix(dfx8rebates,'Unnamed'), axis=1, inplace=True)\n",
        "#    #df['is_x8_track'] = df['itsp_track_sym'].isin(dfx8rebates.index.values).astype(int)\n",
        "#    #cols_rebate = ['rebate_pct_{}' + ]\n",
        "#    return dfx8rebates.drop(['Track'], axis=1)/100.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_b7tjxc37zE",
        "colab_type": "code",
        "outputId": "fccdf00a-3c81-433f-b9f8-7198e6ab97eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#os.chdir('/content/drive/My Drive/Ben/DMM/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUA9bKQmD82h",
        "colab_type": "code",
        "outputId": "7e90f486-acdd-4d37-e8dd-09dbd415a715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Ben/DMM'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puEiB1hkHQXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZvqNYe19quU",
        "colab_type": "text"
      },
      "source": [
        "A wrapper and pipeline function to track each transformation and cleaning step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          2
        ],
        "id": "IWAjKVpX37zP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loggg(f):\n",
        "    \"\"\"A decorator function to wrap data pipeline\"\"\"\n",
        "    def wrapper(df, *args, **kwargs):\n",
        "        tic = dt.datetime.now()\n",
        "        print(f\"{f.__name__} uses {*args, *kwargs}\")\n",
        "        result = f(df, *args, **kwargs)\n",
        "        toc = dt.datetime.now()\n",
        "        print(f\"{f.__name__} took {toc - tic} shape={result.shape}\")\n",
        "        return result\n",
        "    return wrapper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-B9jJ0F37zS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@loggg\n",
        "def start_pipeline(df):\n",
        "    return df.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "ymEzgRdo37zU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@loggg\n",
        "def add_num_nulls_race_by_attr(df, attr):\n",
        "    \"\"\"df: df with 'race_id' \n",
        "    attr: any attribute to count nulls by race\n",
        "    groups by race_id and counts nulls\"\"\"\n",
        "    df['num_null_{}'.format(attr)] = df.groupby('race_id')[attr].transform(lambda x:x.isnull().sum()).astype(int)\n",
        "    print(\"added column num_null_{}\".format(attr))\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          7
        ],
        "id": "Zq9u6ICF37zV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@loggg\n",
        "def get_clean_races_attr(df, attr):\n",
        "    \"\"\"Takes races with no scratches\n",
        "    and no null HDWPSR\"\"\"\n",
        "    df = df[df['num_null_{}'.format(attr)]==0]\n",
        "    return df\n",
        "@loggg\n",
        "def get_clean_races_scratch(df):\n",
        "    \"\"\"Gets only races where num_starters_pre == num_starters_post\n",
        "    and num_starters_starters gt than min_starters\"\"\"\n",
        "    df=df[df.num_starters_pre == df.num_starters_post]\n",
        "    return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "lPTlIyas37zX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@loggg\n",
        "def add_rank_L2SF(df, attr):\n",
        "    \"\"\"ranks L2SF : Largest2Smallest tiebreak 'first' \n",
        "    Assumes sorted by post_position 1,2,3,..\"\"\"\n",
        "    #df = df.groupby('race_id', as_index=False).apply(lambda df: df.sort_values(by=by))\n",
        "    df['rank_{}_L2S'.format(attr)] = df.groupby('race_id')[attr].transform(\n",
        "        lambda x: x.rank(ascending=False, method='first'))\n",
        "    print('added col: rank_{}_L2S'.format(attr))\n",
        "    return df\n",
        "\n",
        "@loggg\n",
        "def add_DiffFromTo(df, attr, ascending):\n",
        "    \"\"\"\n",
        "    The difference between the R1 and the \n",
        "    returns df[attr].sort_values(ascending=False).diff(axis=0)\n",
        "    \n",
        "       \"\"\"\n",
        "    df['DiffFromTo_{}'.format(attr)] = df.groupby('race_id')[attr].transform(lambda x:x.sort_values(ascending=ascending).diff().cumsum().abs())\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zdDaJaA37zZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@loggg\n",
        "def convert_dates(df):\n",
        "    cols_pp_dates = cols_prefix(df, 'pp_date')\n",
        "    cols_wk_dates = cols_prefix(df, 'wk_date')\n",
        "    cols_other_dates = ['date', 'runner_birthdate_year', 'runner_birthdate_act']\n",
        "    cols_dates = cols_pp_dates + cols_wk_dates + cols_other_dates\n",
        "    df[cols_dates] = df[cols_dates].applymap(pd.to_datetime)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          3,
          12,
          22
        ],
        "id": "-FTs18vC37zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@loggg\n",
        "def clean_cols_TTW(df):\n",
        "    \"\"\"Replace 9999 values with 0. for\"\"\"\n",
        "    cols_PED = ['runner_pedigree_HDWDirt',\n",
        "     'runner_pedigree_HDWMud',\n",
        "     'runner_pedigree_HDWTurf',\n",
        "     'runner_pedigree_HDWDist']\n",
        "    df[cols_PED] = df[cols_PED].fillna(0)\n",
        "    df[cols_PED] = df[cols_PED].applymap(lambda x: x if x<9999 else 0)\n",
        "    return df\n",
        "\n",
        "@loggg\n",
        "def add_columns_TTW(df):\n",
        "    df['race_surface'] = df['race_surface'].astype('category')\n",
        "    df['TTW_isDIRT'] = df['race_surface'].isin(['D','d']).astype(int)\n",
        "    if 'track_condition_code' in cols_prefix(df,'track_condition_code'):\n",
        "        df['TTW_isGOOD'] = df['track_condition_code'].isin(['FST','FM','GD']).astype(int)\n",
        "        df['cat_TKCOND'] = df['track_condition_code'].astype('category')\n",
        "    df['is_NEGDIST'] = df['race_distance'].map(lambda x:x<0).astype(int)\n",
        "    df['numDIST'] = df['race_distance'].map(lambda x:abs(x))\n",
        "    return df\n",
        "@loggg\n",
        "def add_TTW_rscore(df):\n",
        "    cols_rank_PED = cols_prefix(df, 'rank_runner')\n",
        "    cols_rank1 = ['isR1_'+ c  for c in cols_rank_PED]\n",
        "    df[cols_rank1] = df[cols_rank_PED].applymap(lambda x:int(x==1))\n",
        "    df['score_R1'] = df[cols_rank1].sum(axis=1)\n",
        "    return df\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKGTMqVs9i8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@loggg\n",
        "def add_wk_days_since_lastrace(df, col_date_pp='pp_date_0'):\n",
        "    \"\"\"\n",
        "    for each workout date subtract date from 'pp_date_0' or other reference date column\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    #df[col_date_pp] = df[col_date_pp].map(pd.to_datetime) #Convert last race date to datetime\n",
        "    \n",
        "    gen_names_wk = lambda x: [x + '_' + str(wknum) for wknum in range(1, 13)]\n",
        "    cols_wkdate = gen_names_wk('wk_date')  #wk_date_1 , wk_date_2, ...wk_date_10\n",
        "    print(cols_wkdate)\n",
        "    df[cols_wkdate] = df[cols_wkdate].applymap(pd.to_datetime)\n",
        "    \n",
        "    dfdays = df[gen_names_wk('wk_date')]-df[col_date_pp].values[:,None]\n",
        "    print(dfdays.head())\n",
        "    colnames_days_since_last_race_date = gen_names_wk('wk_days_since_last_race')\n",
        "    df[colnames_days_since_last_race_date] = dfdays  #add into original frame   \n",
        "    #dfdays = pd.concat([df.apply(lambda dfrow: dfrow[wkcol]-dfrow[col_date_pp], axis=1) for wkcol in cols_wk_date] ,axis=1)\n",
        "    #number of days between workout date and last race\n",
        "    #pd.concat([dfAQU.apply(lambda dfrow: dfrow[wkcol]-dfrow[col_date_pp], axis=1) for wkcol in cols_wk_dates] ,axis=1)\n",
        "    return df\n",
        "\n",
        "\n",
        "@loggg\n",
        "def add_num_wk_since_lastrace(df):\n",
        "    cols_wk_days_since_last_race = cols_prefix(df, 'wk_days_since_last_race')\n",
        "    assert len(cols_wk_days_since_last_race) ==12\n",
        "    colnames_wk_is_since_last_race = gen_names_wk('wk_is_since_last_race')\n",
        "    df[colnames_wk_is_since_last_race] = df[cols_wk_days_since_last_race].applymap(lambda x:int(x.days>0))\n",
        "    df[colnames_wk_is_since_last_race].head()\n",
        "    df['num_wk_since_last_race'] = df[colnames_wk_is_since_last_race].sum(axis=1) \n",
        "    return df\n",
        "\n",
        "@loggg\n",
        "def add_bin7_days_since_last_race(df, step, col_numDSLR):\n",
        "    df['bin_days_since_last_race'] = pd.cut(df.loc[:,col_numDSLR], bins = np.arange(0,2000,step))\n",
        "    return df\n",
        "@loggg\n",
        "def add_qbin4_days_since_last_race(df):\n",
        "    df['qbin4'] = pd.qcut(df.days_since_last_race,4)\n",
        "    return df\n",
        "@loggg\n",
        "def add_btn_lost_last_3(df):\n",
        "    \"\"\"(btn_0 + btn_1 + btn_2)^2 / (btn_0 + btn_1 + btn_2)^2 + (lost_0+lost_1+lost_2)^2 \"\"\"\n",
        "    cols_btn = cols_prefix(df, 'x8btn')\n",
        "    cols_lost = cols_prefix(df, 'x8lost')\n",
        "    df['btn_last_3'] = df[cols_btn].sum(axis=1)\n",
        "    df['lost_last_3'] = (df[cols_lost].sum(axis=1))\n",
        "    df['ratio_btnlost_3'] = np.power(df['btn_last_3'],2) / (np.power(df['btn_last_3'],2) + np.power(df['lost_last_3'],2))\n",
        "    #df['btn_lost_sq_ratio'] = df['btn_last_3']*df['btn_last_3'] / 'lost_last_3']].apply(lambda b,l : np.power(b,2)/((np.power(b,2) + np.power(l,2))), axis=1)\n",
        "    print(df['ratio_btnlost_3']).head()\n",
        "    return df\n",
        "    \n",
        "\n",
        "@loggg\n",
        "def add_NWclass_by_epoch(df, epoch):\n",
        "    \"\"\" Adds NW eligibiily by epoch\n",
        "    'lifetime', 'currentYear', 'prevYear'\"\"\"\n",
        "    map_NWclass = {0 : 'M',\n",
        "                  1 : 'NW2',\n",
        "                  2: 'NW3',\n",
        "                  3: 'NW4'}\n",
        "    # bucket wine quality scores into qualitative quality labels\n",
        "    df['NW_class_{}'.format(epoch)] = df['runner_horse_{}_wins'.format(epoch)].map(lambda wins: map_NWclass.get(wins, 'GT3'))\n",
        "    return df\n",
        "    \n",
        "\n",
        "@loggg\n",
        "def add_is_win_last_race(df, col_lastracefinish):\n",
        "    \"\"\"\n",
        "    df: DataFrame\n",
        "    col_finish_last: 'pp_call_finish_pos_0' if using pp files\n",
        "                     'last_race_finish' if using result files  \"\"\"\n",
        "    \n",
        "    df['isWLR'] = df[col_lastracefinish].map(lambda x: int(x==1))\n",
        "    return df\n",
        "\n",
        "@loggg\n",
        "def add_num_winners_last_race(df, col_isWLR):\n",
        "    df['numWLR'] = df.groupby('race_id')[col_isWLR].transform(sum)\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "@loggg\n",
        "def add_residual_earnings(df):\n",
        "    df.loc[:,'runner_horse_residual_earnings'] = df.loc[:, 'runner_horse_lifetime_earnings'] -  df.loc[:, 'runner_horse_currentYear_earnings'] - df.loc[:, 'runner_horse_prevYear_earnings']\n",
        "    df.loc[:,'runner_horse_residual_starts'] = df.loc[:, 'runner_horse_lifetime_starts'] -  df.loc[:, 'runner_horse_currentYear_starts'] - df.loc[:, 'runner_horse_prevYear_starts']\n",
        "    return df\n",
        "@loggg\n",
        "def add_runner_earnings_per_start_factors(df):\n",
        "    \"\"\"computes earnings per start for a given group \"\"\"\n",
        "    df.loc[:,'eps_lifetime'] = (df.loc[:,'runner_horse_lifetime_earnings']/df.loc[:,'runner_horse_lifetime_starts']).fillna(0)\n",
        "    df.loc[:,'eps_currentYear'] = (df.loc[:,'runner_horse_currentYear_earnings']/df.loc[:,'runner_horse_currentYear_starts']).fillna(0)\n",
        "    df.loc[:,'eps_prevYear'] = (df.loc[:,'runner_horse_prevYear_earnings']/df.loc[:,'runner_horse_prevYear_starts']).fillna(0)\n",
        "    df.loc[:,'eps_distance'] = (df.loc[:,'runner_horse_lifetime_earnings_distance']/df.loc[:,'runner_horse_lifetime_starts_distance']).fillna(0)\n",
        "    df.loc[:,'eps_residual'] = (df.loc[:,'runner_horse_residual_earnings']/df.loc[:,'runner_horse_residual_starts']).fillna(0)\n",
        "    #df.loc[:,'eps_ppstarts'] = (df.loc[:,'runner_horse_earnings_pp_total']/df.loc[:,'num_starts_from_pp_earnings']).fillna(0)\n",
        "\n",
        "    #df.loc[:,'eps_pp_total'] = (df.loc[:,'runner_horse_earnings_pp_total']/df.loc[:,'runner_horse_earnings_']).fillna(0)\n",
        "    return df\n",
        "\n",
        "@loggg\n",
        "def add_rank_eps(df):\n",
        "    df['rank_eps_lifetime'] = df.groupby('race_id')['eps_lifetime'].transform(lambda x: x.rank(method='first',ascending=False))\n",
        "    df['rank_eps_currentYear'] = df.groupby('race_id')['eps_currentYear'].transform(lambda x: x.rank(method='first',ascending=False))\n",
        "    df['rank_eps_prevYear'] = df.groupby('race_id')['eps_prevYear'].transform(lambda x: x.rank(method='first',ascending=False))\n",
        "    df['rank_eps_distance'] = df.groupby('race_id')['eps_distance'].transform(lambda x: x.rank(method='first',ascending=False))\n",
        "    df['rank_eps_residual'] = df.groupby('race_id')['eps_residual'].transform(lambda x: x.rank(method='first',ascending=False))\n",
        "    #df['rank_eps_ppstarts'] = df.groupby(level='race_id')['eps_ppstarts'].transform(lambda x: x.rank(method='first',ascending=False))\n",
        "\n",
        "    return df\n",
        "\n",
        "@loggg\n",
        "def add_quality_num_scratches(df, col_pre, col_post):\n",
        "    df['num_scratches'] = (df.loc[:,'num_starters_pre_jcp'].fillna(0) - df.loc[:,'num_starters_post_jcp'].fillna(0)).astype(int)\n",
        "    df['quality_scratch'] = df['num_scratches'].apply(lambda value: 'clean' if value == 0 else\n",
        "                                                     'single' if value == 1 else\n",
        "                                                     'dirty')\n",
        "\n",
        "@loggg\n",
        "def add_quality_HDWPSR(df):\n",
        "    df['quality_label_race_HDWPSR'] = df['num_isnull_hdw'].apply(lambda value: 'clean' if value == 0 else 'dirty')\n",
        "    df['quality_HDWPSR'] = pd.Categorical(df['quality_label_race_HDWPSR'], categories=['clean','dirty'])\n",
        "    return df\n",
        "\n",
        "@loggg\n",
        "def add_quality_num_scratches(df):\n",
        "    col_pre = cols_prefix('num_starters_pre')[0]\n",
        "    col_post = cols_prefix('num_starters_post')[0]\n",
        "\n",
        "    df['num_scratches'] = (df.loc[:, cols_pre].fillna(0) - df.loc[:,col_post].fillna(0)).astype(int)\n",
        "    df['quality_scratch'] = df['num_scratches'].apply(lambda value: 'clean' if value == 0 else\n",
        "                                                     'single' if value == 1 else\n",
        "                                                     'dirty')\n",
        "    return df\n",
        "\n",
        "@loggg\n",
        "def add_pp_beaten(df):\n",
        "    \"\"\" for each pp_race determine how many horses were beaten\"\"\"\n",
        "    cols_btn = ['ppx8_beaten_{}'.format(pp) for pp in range(10)]\n",
        "    cols_pp_field = cols_prefix(df, 'pp_fieldsize')\n",
        "    cols_pp_finish = cols_prefix(df, 'pp_call_finish_pos')\n",
        "    df[cols_btn] = np.subtract(df[cols_pp_field],df[cols_pp_finish])\n",
        "    return df\n",
        "@loggg\n",
        "def add_pp_lost(df):\n",
        "    \"\"\" for each pp_race determine how many horses were lost to \"\"\"\n",
        "    cols_lost = ['ppx8_lost_{}'.format(pp) for pp in range(10)]\n",
        "    cols_btn = cols_prefix(df, 'ppx8_beaten')\n",
        "    cols_pp_field = cols_prefix(df, 'pp_fieldsize')\n",
        "    cols_pp_finish = cols_prefix(df, 'pp_call_finish_pos')\n",
        "    df[cols_lost] = np.subtract(df[cols_pp_field],df[cols_btn] + 1)\n",
        "    return df\n",
        "\n",
        "@loggg\n",
        "def add_pp_pct_beaten(df):\n",
        "    \"\"\" for each pp_race compute pct of field beaten \"\"\"\n",
        "    cols_pp_pct_beaten = ['ppx8_pct_beaten_{}'.format(pp) for pp in range(10)]\n",
        "    cols_btn = cols_prefix(df, 'ppx8_beaten')\n",
        "    cols_pp_field = cols_prefix(df, 'pp_fieldsize')\n",
        "    #cols_pp_finish = cols_prefix(df, 'pp_call_finish_pos')\n",
        "    df[cols_pp_pct_beaten] = np.divide(df[cols_btn],df[cols_pp_field])\n",
        "    return df\n",
        "\n",
        "@loggg\n",
        "def add_pp_dollars_per_runner(df):\n",
        "    \"\"\"for reach pp race compute the dollars per runner \"\"\"\n",
        "    cols_dollars_per_runner = ['x8dpr_{}'.format(pp) for pp in range(10)]  \n",
        "    cols_pp_purse = cols_prefix(df,'pp_purse')\n",
        "    cols_pp_field = cols_prefix(df,'pp_field')\n",
        "    df[cols_dollars_per_runner] = np.divide(df[cols_pp_purse],df[cols_pp_field])\n",
        "    return df\n",
        "    \n",
        "@loggg\n",
        "def add_pp_dollars_beaten(df):\n",
        "    cols_dollars_per_runner = cols_prefix(df,'x8dpr_')\n",
        "    cols_btn = cols_prefix(df,'ppx8_beaten_')\n",
        "    cols_dollars_beaten = ['ppx8_dollarsBeaten_{}'.format(pp) for pp in range(10)]\n",
        "    df[cols_dollars_beaten] = np.multiply(df[cols_btn], df[cols_dollars_per_runner])\n",
        "    return df\n",
        "\n",
        "@loggg\n",
        "def add_mean_dollars_beaten_lastN(df, n):\n",
        "    cols_dollars_beaten = cols_prefix(df,'ppx8_dollarsBeaten_')\n",
        "    #df['sum_ppx8_dollars_beaten_last3'] = df[cols_dollars_beaten].iloc[:,0:n].sum(axis=1)\n",
        "    df['mean_ppx8_dollars_beaten_last3'] = df[cols_dollars_beaten].iloc[:,0:n].mean(axis=1)\n",
        "    return df\n",
        "\n",
        "@loggg\n",
        "def add_sum_dollars_beaten_lastN(df, n):\n",
        "    cols_dollars_beaten = cols_prefix(df,'ppx8_dollarsBeaten_')\n",
        "    #df['sum_ppx8_dollars_beaten_last3'] = df[cols_dollars_beaten].iloc[:,0:n].sum(axis=1)\n",
        "    df['sum_ppx8_dollars_beaten_last3'] = df[cols_dollars_beaten].iloc[:,0:n].sum(axis=1)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1S8QHTu8qwl",
        "colab_type": "text"
      },
      "source": [
        "### Some convenience functions for finding and naming columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d80okVmX-dAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_columns(df):\n",
        "    \"\"\"\n",
        "    Removes '_pp' from pp columns\n",
        "\n",
        "    \"\"\"\n",
        "    df.columns = list(map(lambda x: x.replace('_pp', ''), df.columns))\n",
        "    df.drop(cols_prefix(df, 'wager_'), inplace=True, axis=1)\n",
        "    df.drop(cols_prefix(df, 'race_reserved'), inplace=True, axis=1)\n",
        "    df.drop(cols_prefix(df, 'race_blank'), inplace=True, axis=1)\n",
        "    df.drop(cols_prefix(df, 'pp_reserved'), inplace=True, axis=1)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYcupdiH8o62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "cols_prefix = lambda df, txt: [c for c in df.columns if c.startswith(txt)]\n",
        "cols_suffix = lambda df, txt: [c for c in df.columns if c.endswith(txt)]\n",
        "\n",
        "vals_around = lambda df, cols, thresh, around: df[cols].applymap(lambda x: abs(x - thresh) < around)\n",
        "# Column name generator\n",
        "gen_names_wk = lambda x: [x + '_' + str(wknum) for wknum in range(1, 13)]\n",
        "\n",
        "# generating column names\n",
        "def gen_ppnames_dr(factor='speed_HDW', prefix='pp', suffix=None):\n",
        "    \"\"\"\n",
        "    generates a list of pp column names for reading or adding\n",
        "    i.e. if I know the factor name I can generate the column names\n",
        "    i.e. if I want to add columns I can generate the new names in a similar format\n",
        "    :param factor: 'speed_HDW' (a factor_name from DailyRaces pp  ie. 'speed_HDW)\n",
        "    :param prefix: 'pp'\n",
        "    :param suffix: 'pp'\n",
        "    :return: ['pp_speed_HDW_0_pp', 'pp_speed_HDW_1_pp', ..., pp_speed_HDW_9_pp']\n",
        "    \"\"\"\n",
        "    if (suffix):\n",
        "        namespp = [prefix + \"_\" + factor + \"_\" + str(pp) + \"_\" + suffix for pp in range(10)]\n",
        "    else:\n",
        "        namespp = [prefix + \"_\" + factor + \"_\" + str(pp) for pp in range(10)]\n",
        "\n",
        "    return namespp\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX69smw86kTN",
        "colab_type": "text"
      },
      "source": [
        "# Load Historical PastPerformance DataFrame "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTFLpG5S8zIN",
        "colab_type": "text"
      },
      "source": [
        "Load the historical dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eQAIzTb6xZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## The output from current loader is in this file\n",
        "dfhist = pd.read_csv('dfhist_DMM.csv.gz',low_memory=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neayoAQMAUJM",
        "colab_type": "text"
      },
      "source": [
        "### Start the pipeline and generate columns for TTW model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Konracka6h5q",
        "colab_type": "code",
        "outputId": "e0aa41b9-85e5-4fd0-cacc-896e8ccd42d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "source": [
        "#Start the pipeline to clean the data\n",
        "\n",
        "dfhist_clean = start_pipeline(dfhist)\\\n",
        ".pipe(add_num_nulls_race_by_attr,'runner_HDWPSRRating')\\\n",
        ".pipe(get_clean_races_attr, 'runner_HDWPSRRating')\\\n",
        ".pipe(clean_cols_TTW)\\\n",
        ".pipe(add_rank_L2SF,'runner_pedigree_HDWDirt')\\\n",
        ".pipe(add_rank_L2SF, 'runner_pedigree_HDWDist')\\\n",
        ".pipe(add_rank_L2SF, 'runner_pedigree_HDWMud')\\\n",
        ".pipe(add_rank_L2SF, 'runner_pedigree_HDWTurf')\\\n",
        ".pipe(add_rank_L2SF, 'runner_HDWPSRRating')\\\n",
        ".pipe(add_columns_TTW)\\\n",
        ".pipe(add_TTW_rscore)\\\n",
        ".pipe(add_DiffFromTo, attr='runner_HDWPSRRating', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start_pipeline uses ()\n",
            "start_pipeline took 0:00:00.268273 shape=(24550, 1456)\n",
            "add_num_nulls_race_by_attr uses ('runner_HDWPSRRating',)\n",
            "added column num_null_runner_HDWPSRRating\n",
            "add_num_nulls_race_by_attr took 0:00:01.490967 shape=(24550, 1457)\n",
            "get_clean_races_attr uses ('runner_HDWPSRRating',)\n",
            "get_clean_races_attr took 0:00:00.130815 shape=(19750, 1457)\n",
            "clean_cols_TTW uses ()\n",
            "clean_cols_TTW took 0:00:00.032985 shape=(19750, 1457)\n",
            "add_rank_L2SF uses ('runner_pedigree_HDWDirt',)\n",
            "added col: rank_runner_pedigree_HDWDirt_L2S\n",
            "add_rank_L2SF took 0:00:00.979137 shape=(19750, 1458)\n",
            "add_rank_L2SF uses ('runner_pedigree_HDWDist',)\n",
            "added col: rank_runner_pedigree_HDWDist_L2S\n",
            "add_rank_L2SF took 0:00:01.201124 shape=(19750, 1459)\n",
            "add_rank_L2SF uses ('runner_pedigree_HDWMud',)\n",
            "added col: rank_runner_pedigree_HDWMud_L2S\n",
            "add_rank_L2SF took 0:00:00.998985 shape=(19750, 1460)\n",
            "add_rank_L2SF uses ('runner_pedigree_HDWTurf',)\n",
            "added col: rank_runner_pedigree_HDWTurf_L2S\n",
            "add_rank_L2SF took 0:00:01.074353 shape=(19750, 1461)\n",
            "add_rank_L2SF uses ('runner_HDWPSRRating',)\n",
            "added col: rank_runner_HDWPSRRating_L2S\n",
            "add_rank_L2SF took 0:00:01.134717 shape=(19750, 1462)\n",
            "add_columns_TTW uses ()\n",
            "add_columns_TTW took 0:00:00.069848 shape=(19750, 1465)\n",
            "add_TTW_rscore uses ()\n",
            "add_TTW_rscore took 0:00:00.185063 shape=(19750, 1471)\n",
            "add_DiffFromTo uses ('attr', 'ascending')\n",
            "add_DiffFromTo took 0:00:02.629291 shape=(19750, 1472)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khP_Z3y2ANLU",
        "colab_type": "text"
      },
      "source": [
        "# "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6GgniEoAbua",
        "colab_type": "text"
      },
      "source": [
        "### Now continue the pipeline adding columns for SMM, CCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtIWjQka99ir",
        "colab_type": "code",
        "outputId": "1ea7d02c-5610-43ec-a8bc-d4ed489c8160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        }
      },
      "source": [
        "\n",
        "#Cleaning pipeline history all tracks\n",
        "dfhist_clean = start_pipeline(dfhist_clean)\\\n",
        ".pipe(clean_columns)\\\n",
        ".pipe(convert_dates)\\\n",
        ".pipe(add_wk_days_since_lastrace)\\\n",
        ".pipe(add_num_wk_since_lastrace)\\\n",
        ".pipe(add_bin7_days_since_last_race, step=7, col_numDSLR='days_since_last_race')\\\n",
        ".pipe(add_NWclass_by_epoch, 'lifetime')\\\n",
        ".pipe(add_NWclass_by_epoch, 'currentYear')\\\n",
        ".pipe(add_NWclass_by_epoch, 'prevYear')\\\n",
        ".pipe(add_is_win_last_race, col_lastracefinish='pp_call_finish_pos_0')\\\n",
        ".pipe(add_rank_L2SF, 'runner_HDWPSRRating')\\\n",
        ".pipe(add_residual_earnings)\\\n",
        ".pipe(add_runner_earnings_per_start_factors)\\\n",
        ".pipe(add_rank_eps)\\\n",
        ".pipe(add_pp_beaten)\\\n",
        ".pipe(add_pp_lost)\\\n",
        ".pipe(add_pp_pct_beaten)\\\n",
        ".pipe(add_pp_dollars_per_runner)\\\n",
        ".pipe(add_pp_dollars_beaten)\\\n",
        ".pipe(add_mean_dollars_beaten_lastN,3)\\\n",
        ".pipe(add_sum_dollars_beaten_lastN,3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start_pipeline uses ()\n",
            "start_pipeline took 0:00:00.181002 shape=(19750, 1472)\n",
            "convert_dates uses ()\n",
            "convert_dates took 0:00:58.115775 shape=(19750, 1326)\n",
            "add_wk_days_since_lastrace uses ()\n",
            "['wk_date_1', 'wk_date_2', 'wk_date_3', 'wk_date_4', 'wk_date_5', 'wk_date_6', 'wk_date_7', 'wk_date_8', 'wk_date_9', 'wk_date_10', 'wk_date_11', 'wk_date_12']\n",
            "  wk_date_1 wk_date_2 wk_date_3  ... wk_date_10 wk_date_11 wk_date_12\n",
            "0   21 days  -35 days  -85 days  ...  -312 days  -312 days  -312 days\n",
            "1   29 days   21 days   13 days  ...  -167 days  -167 days  -167 days\n",
            "2  -16 days  -48 days  -78 days  ...  -295 days  -295 days  -295 days\n",
            "3   15 days   -4 days  -40 days  ...  -257 days  -257 days  -257 days\n",
            "4   20 days   -2 days   -9 days  ...   -69 days   -69 days   -69 days\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "add_wk_days_since_lastrace took 0:00:01.191080 shape=(19750, 1338)\n",
            "add_num_wk_since_lastrace uses ()\n",
            "add_num_wk_since_lastrace took 0:00:02.207284 shape=(19750, 1351)\n",
            "add_bin7_days_since_last_race uses ('step', 'col_numDSLR')\n",
            "add_bin7_days_since_last_race took 0:00:00.020132 shape=(19750, 1352)\n",
            "add_NWclass_by_epoch uses ('lifetime',)\n",
            "add_NWclass_by_epoch took 0:00:00.005712 shape=(19750, 1353)\n",
            "add_NWclass_by_epoch uses ('currentYear',)\n",
            "add_NWclass_by_epoch took 0:00:00.005782 shape=(19750, 1354)\n",
            "add_NWclass_by_epoch uses ('prevYear',)\n",
            "add_NWclass_by_epoch took 0:00:00.005529 shape=(19750, 1355)\n",
            "add_is_win_last_race uses ('col_lastracefinish',)\n",
            "add_is_win_last_race took 0:00:00.010196 shape=(19750, 1356)\n",
            "add_rank_L2SF uses ('runner_HDWPSRRating',)\n",
            "added col: rank_runner_HDWPSRRating_L2S\n",
            "add_rank_L2SF took 0:00:01.060098 shape=(19750, 1356)\n",
            "add_residual_earnings uses ()\n",
            "add_residual_earnings took 0:00:00.232052 shape=(19750, 1358)\n",
            "add_runner_earnings_per_start_factors uses ()\n",
            "add_runner_earnings_per_start_factors took 0:00:00.376992 shape=(19750, 1363)\n",
            "add_rank_eps uses ()\n",
            "add_rank_eps took 0:00:05.152608 shape=(19750, 1368)\n",
            "add_pp_beaten uses ()\n",
            "add_pp_beaten took 0:00:00.086126 shape=(19750, 1378)\n",
            "add_pp_lost uses ()\n",
            "add_pp_lost took 0:00:00.088433 shape=(19750, 1388)\n",
            "add_pp_pct_beaten uses ()\n",
            "add_pp_pct_beaten took 0:00:00.084247 shape=(19750, 1398)\n",
            "add_pp_dollars_per_runner uses ()\n",
            "add_pp_dollars_per_runner took 0:00:00.078613 shape=(19750, 1408)\n",
            "add_pp_dollars_beaten uses ()\n",
            "add_pp_dollars_beaten took 0:00:00.088202 shape=(19750, 1418)\n",
            "add_mean_dollars_beaten_lastN uses (3,)\n",
            "add_mean_dollars_beaten_lastN took 0:00:00.082624 shape=(19750, 1419)\n",
            "add_sum_dollars_beaten_lastN uses (3,)\n",
            "add_sum_dollars_beaten_lastN took 0:00:00.078487 shape=(19750, 1420)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xduH4FBC-FdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfhist_clean.to_csv('dfhist_clean.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTjmCrV_BTep",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}